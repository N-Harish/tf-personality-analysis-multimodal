{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f044e02c-5a72-4d58-b658-6138dd8000a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-04 08:28:47.548604: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-02-04 08:28:49.265180: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2023-02-04 08:28:49.671659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: NVIDIA A100-SXM4-40GB computeCapability: 8.0\n",
      "coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s\n",
      "2023-02-04 08:28:49.671712: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-02-04 08:28:49.676619: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2023-02-04 08:28:49.676717: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-02-04 08:28:49.678182: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2023-02-04 08:28:49.678556: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2023-02-04 08:28:49.679197: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2023-02-04 08:28:49.680243: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-02-04 08:28:49.680461: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-02-04 08:28:49.684436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tensorflow.keras import mixed_precision\n",
    "import transformers\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import concatenate, Dense\n",
    "import pickle\n",
    "\n",
    "\n",
    "# enable tf debugging\n",
    "# tf.debugging.experimental.enable_dump_debug_info('./logs_tfboard/tfds_dumps/', tensor_debug_mode=\"FULL_HEALTH\")\n",
    "\n",
    "\n",
    "# stop tf from using all gpu memory and use only as much required\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd420125-251e-466f-b244-6da385c7ff6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as k\n",
    "\n",
    "\n",
    "def mean_acc(y_true, y_pred):\n",
    "    diff = k.abs(y_true - y_pred)\n",
    "    return k.mean(1-diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1636949-f242-4841-8d0e-3450ba72293d",
   "metadata": {},
   "source": [
    "# load all model embeddings/ defining multimodal (4 models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050476dc-59ad-44fb-980f-a513541f3a81",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Uncomment below codes to change multimodal architechture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f259586-83c0-4e40-bda5-bab9ce14190b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-04 08:28:50.047496: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-04 08:28:50.100675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: NVIDIA A100-SXM4-40GB computeCapability: 8.0\n",
      "coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s\n",
      "2023-02-04 08:28:50.104742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2023-02-04 08:28:50.104836: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-02-04 08:28:52.507576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-02-04 08:28:52.507604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2023-02-04 08:28:52.507612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2023-02-04 08:28:52.513731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 38316 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0)\n"
     ]
    }
   ],
   "source": [
    "model_env = load_model(\n",
    "    \"/mount1/harish/Personality_trait/checkpoint/00004-env_personality/env-personality-model-04-0.12.h5\",\n",
    "    custom_objects={\"mean_acc\": mean_acc}\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97ee8e42-539d-47c1-9fe6-76f06fba7b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save frame model \n",
    "# model.save(\"env_personality.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520f5387-76a7-4efc-9c18-01ea1380f3a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b796477-fd45-48f4-9bce-deb6426555bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_face = load_model(\n",
    "    \"/mount1/harish/Personality_trait/checkpoint/face_personality/00008-face_personality/face-personality-model-05-0.12.h5\", \n",
    "    custom_objects = {\"mean_acc\": mean_acc}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "975d436b-89a2-4ecc-928e-e1117817af6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save face model\n",
    "# model_face.save(\"face_personality.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d576020c-a639-46db-ac02-d57b034af0e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "940117ae-cae2-49ed-9775-4cc82fc6a124",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_aud = load_model(\"/mount1/harish/Personality_trait/checkpoint/audio_personality/00008-audio_personality/audio-personality-model-11-0.11.h5\", \n",
    "                      custom_objects={\"mean_acc\": mean_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fed7321-bd10-4c7f-bbc2-1d8f770a12f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save audio model\n",
    "# model_aud.save(\"audio_personality_par_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87be89f9-ae23-4761-8063-b344eb5e7d41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5870004-8c68-4b34-a8b4-7e83d054c4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_text = load_model(\n",
    "#     \"/mount1/harish/Personality_trait/checkpoint/00015-text_personality/text-personality-model-16-0.12.h5\",\n",
    "#     custom_objects={\"mean_acc\": mean_acc, \"TFBertModel\": transformers.TFBertModel}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d91a19f-917c-4572-9ec6-3e7ce2520200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save text model\n",
    "# model_text.save(\"text_personality_ocean.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "569fff35-143f-47ce-9298-958750a48ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function input_processing at 0x7ff628c1cb80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: '<' not supported between instances of 'Literal' and 'str'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function input_processing at 0x7ff628c1cb80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: '<' not supported between instances of 'Literal' and 'str'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:From /mount1/miniconda3/envs/tfgpu2.5/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_path = \"text_personality_ocean.h5\"\n",
    "\n",
    "custom_objects={\"mean_acc\": mean_acc, \"TFBertModel\": transformers.TFBertModel}\n",
    "\n",
    "model_text = load_model(model_path, custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05093db7-3395-4215-9ce3-be57b2945787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all pretrained model\n",
    "model_face.trainable = False\n",
    "model_aud.trainable = False\n",
    "model_text.trainable = False\n",
    "model_env.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acde368-403d-4c72-a738-666162364a1c",
   "metadata": {},
   "source": [
    "## Building multimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22eb0f41-bf17-431d-91e4-c29a662c004b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_token (InputLayer)        [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masked_token (InputLayer)       [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 109482240   input_token[0][0]                \n",
      "                                                                 masked_token[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 768)          0           tf_bert_model[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "txt_emb (Dense)                 (None, 128)          98432       global_average_pooling1d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 109,580,672\n",
      "Trainable params: 98,432\n",
      "Non-trainable params: 109,482,240\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create text emb model\n",
    "op_txt = Dense(128, name='txt_emb')(model_text.get_layer(\"global_average_pooling1d\").output)\n",
    "\n",
    "model_text_emb = Model(inputs=model_text.input, outputs=op_txt)\n",
    "# model_text_emb.trainable = False\n",
    "model_text_emb.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ea991b8-cf9e-4b3e-b2df-043ed0c31117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 30, 224, 224, 3)] 0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 30, 2048)          42626560  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               2360320   \n",
      "=================================================================\n",
      "Total params: 44,986,880\n",
      "Trainable params: 0\n",
      "Non-trainable params: 44,986,880\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create frame emb model\n",
    "model_env_emb = Model(inputs=model_env.input, outputs=model_env.get_layer(\"lstm_1\").output)\n",
    "# model_env_emb.trainable = False\n",
    "model_env_emb.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b27ebf1-f2fa-4b8d-969e-f9adff62ea92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 30, 224, 224, 3)] 0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 30, 2048)          23564800  \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 256)               2360320   \n",
      "=================================================================\n",
      "Total params: 25,925,120\n",
      "Trainable params: 0\n",
      "Non-trainable params: 25,925,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create face emb model\n",
    "model_face_emb = Model(inputs=model_face.input, outputs=model_face.get_layer(\"lstm\").output)\n",
    "# model_face_emb.trainable = False\n",
    "model_face_emb.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7edc18a-42d9-4327-96f5-c238bd0e6bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_embedding (InputLayer) [(None, 1024)]            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "aud_emb (Dense)              (None, 256)               131328    \n",
      "=================================================================\n",
      "Total params: 656,128\n",
      "Trainable params: 131,328\n",
      "Non-trainable params: 524,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create aud emb model\n",
    "aud_op = Dense(256, name='aud_emb')(model_aud.get_layer(\"dense_2\").output)\n",
    "\n",
    "model_aud_emb = Model(inputs=model_aud.inputs, outputs = aud_op)\n",
    "model_aud_emb.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc7d3f6-dd36-4a32-896c-fa3bc884863a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c508782-0913-4a2d-8f36-65a47f9b3966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_token (InputLayer)        [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masked_token (InputLayer)       [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 30, 224, 224 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 30, 224, 224 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_embedding (InputLayer)    [(None, 1024)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 109482240   input_token[0][0]                \n",
      "                                                                 masked_token[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 30, 2048)     42626560    input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 30, 2048)     23564800    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          524800      input_embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 768)          0           tf_bert_model[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 256)          2360320     time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 256)          2360320     time_distributed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "aud_emb (Dense)                 (None, 256)          131328      dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "txt_emb (Dense)                 (None, 128)          98432       global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 896)          0           lstm_1[0][0]                     \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 aud_emb[0][0]                    \n",
      "                                                                 txt_emb[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_comb (Dense)              (None, 512)          459264      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_comb1 (Dense)             (None, 256)          131328      dense_comb[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_op (Dense)                (None, 5)            1285        dense_comb1[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 181,740,677\n",
      "Trainable params: 821,637\n",
      "Non-trainable params: 180,919,040\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create multimodal\n",
    "concat_inp = concatenate([model_env_emb.output, model_face_emb.output, model_aud_emb.output, model_text_emb.output])\n",
    "x = Dense(512, activation=\"relu\", name=\"dense_comb\")(concat_inp)\n",
    "x = Dense(256, activation=\"relu\", name=\"dense_comb1\")(x)\n",
    "x = Dense(5, activation=\"sigmoid\",  name=\"dense_op\")(x)\n",
    "\n",
    "model = Model(inputs=[model_env_emb.input, model_face_emb.input, model_aud_emb.input, model_text.input], outputs=x)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904903f6-ba2e-4295-b5e8-424923e941f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec320c7-ed9e-4944-aba1-4d8fce4c2013",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040267a5-4fce-4e9a-a1cd-c04d6e877c85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21695c1e-6388-4057-96fc-88c97d6f9ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save multimodal\n",
    "# model.save(\"multimodal_architechture_definition.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1976da6a-8a0d-4d31-b6a1-00fbfb566d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # clear all models\n",
    "# from tensorflow.keras.backend import clear_session\n",
    "# import gc\n",
    "\n",
    "\n",
    "# clear_session()\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d54d04-b882-420d-91f8-7dc1d304cf85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7e41898-1543-4b63-83e3-5f32e4ff1475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Delete all unwanted model\n",
    "# del model_aud\n",
    "# del model_face\n",
    "# del model_text\n",
    "# del model_env\n",
    "# del model_aud_emb\n",
    "# del model_face_emb\n",
    "# del model_env_emb\n",
    "# del model_text_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "587d7623-7dc4-47ee-ab4f-be4a211c3b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load base multimodal architechture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6902f45a-443c-47cd-9ca4-2a77f25122b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model(\"multimodal_architechture_definition.h5\", custom_objects={\"mean_acc\": mean_acc, \"TFBertModel\": transformers.TFBertModel})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b11e7ac4-4b1e-46ab-adc5-035b57fb5551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "574bfa53-342e-4ce3-b409-54a78ba0a47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_token (InputLayer)        [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masked_token (InputLayer)       [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 30, 224, 224 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 30, 224, 224 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_embedding (InputLayer)    [(None, 1024)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 109482240   input_token[0][0]                \n",
      "                                                                 masked_token[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 30, 2048)     42626560    input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 30, 2048)     23564800    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          524800      input_embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 768)          0           tf_bert_model[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 256)          2360320     time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 256)          2360320     time_distributed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "aud_emb (Dense)                 (None, 256)          131328      dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "txt_emb (Dense)                 (None, 128)          98432       global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 896)          0           lstm_1[0][0]                     \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 aud_emb[0][0]                    \n",
      "                                                                 txt_emb[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_comb (Dense)              (None, 512)          459264      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_comb1 (Dense)             (None, 256)          131328      dense_comb[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_op (Dense)                (None, 5)            1285        dense_comb1[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 181,740,677\n",
      "Trainable params: 821,637\n",
      "Non-trainable params: 180,919,040\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42f0400-531a-440b-a314-3deb7c932992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58dd48b0-f000-401b-9569-6f6917882392",
   "metadata": {},
   "source": [
    "# Audio processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea71f0b6-cb50-4baf-a0f8-345ada58ac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for loading audio files and making sure the sample rate is correct.\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def load_wav_16k_mono(filename):\n",
    "    \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    wav, sample_rate = tf.audio.decode_wav(\n",
    "          file_contents,\n",
    "          desired_channels=1)\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e2e7d4e-d1d5-4acf-be87-6323632e4f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_wav_for_map1(filename, label):\n",
    "#     return load_wav_16k_mono(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54e42d67-2c52-4f98-acba-93734642473c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "\n",
    "# load yamnet model\n",
    "yamnet_model_handle = 'https://tfhub.dev/google/yamnet/1'\n",
    "yamnet_model = hub.load(yamnet_model_handle)\n",
    "\n",
    "\n",
    "# applies the embedding extraction model to a wav data\n",
    "@tf.function\n",
    "def extract_embedding(wav_data):\n",
    "    ''' run YAMNet to extract embedding from the wav data '''\n",
    "    \n",
    "    file_contents = tf.io.read_file(wav_data)\n",
    "    wav, sample_rate = tf.audio.decode_wav(\n",
    "          file_contents,\n",
    "          desired_channels=1)\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    wav_data = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "    \n",
    "    scores, embeddings, spectrogram = yamnet_model(wav_data)\n",
    "    print(embeddings)\n",
    "    \n",
    "    # embeddings = tf.math.reduce_mean(embeddings, axis=0)\n",
    "    \n",
    "    num_embeddings = tf.shape(embeddings)[0]\n",
    "    # print(tf.shape(embeddings)[0])\n",
    "    \n",
    "    # use reduce mean to calculate mean of array along axis 1 (mean of column value)\n",
    "    return tf.math.reduce_mean(embeddings, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091f061d-55c6-4d91-b34e-3dd32e7e5a38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b5405bf-2ef5-4714-9bbf-85981f18ca37",
   "metadata": {},
   "source": [
    "# Text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "354c8b48-a086-452e-abb6-2633b537833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "\n",
    "def get_feature_tf_data(filenames):\n",
    "    with open(\"bert_feature.pkl\", 'rb') as f:\n",
    "        train_feature = pkl.load(f)\n",
    "    filenames = filenames.numpy().decode('utf-8')\n",
    "    return np.array(train_feature[filenames]['input_ids']), np.array(train_feature[filenames]['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5714dea7-da78-4ab2-8bc6-fd4dbfbf8bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tf dataset feature for test data\n",
    "\n",
    "def get_feature_tf_data_test(filenames):\n",
    "    with open(\"bert_feature_test.pkl\", 'rb') as f:\n",
    "        train_feature = pkl.load(f)\n",
    "    filenames = filenames.numpy().decode('utf-8')\n",
    "    return np.array(train_feature[filenames]['input_ids']), np.array(train_feature[filenames]['attention_mask']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a82f1d6-e0a1-4d5b-88d5-5f83eb6d04d9",
   "metadata": {},
   "source": [
    "# Video based preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fcea29a1-d768-4fbd-a6db-bcfca842fc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "\n",
    "def format_frames(frame, output_size):\n",
    "    \"\"\"\n",
    "        Pad and resize an image from a video.\n",
    "\n",
    "        Args:\n",
    "          frame: Image that needs to resized and padded. \n",
    "          output_size: Pixel size of the output frame image.\n",
    "\n",
    "        Return:\n",
    "          Formatted frame with padding of specified output size.\n",
    "    \"\"\"\n",
    "    frame = tf.image.convert_image_dtype(frame, tf.float32)\n",
    "    frame = tf.image.resize_with_pad(frame, *output_size)\n",
    "    return tf.keras.applications.resnet_v2.preprocess_input(frame)\n",
    "    # return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6499e363-2053-46a2-b461-83d84bba67bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf dataset generator\n",
    "class MetaGenerator:\n",
    "    def __init__(self, df, n_frames, training = False):\n",
    "        \"\"\" Returns a set of frames with their associated label. \n",
    "            Args:\n",
    "                path: Video file paths.\n",
    "                n_frames: Number of frames. \n",
    "                training: Boolean to determine if training dataset is being created.\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.n_frames = n_frames\n",
    "        self.training = training\n",
    "  \n",
    "\n",
    "    def __call__(self):\n",
    "        if self.training:\n",
    "            import sklearn\n",
    "            self.df = sklearn.utils.shuffle(self.df)\n",
    "            \n",
    "        for files in self.df.itertuples():\n",
    "            # video_frames = frames_from_video_file(files.file_path, self.n_frames)\n",
    "            video_frames = files.file_path\n",
    "            openness = files.openness\n",
    "            conscientiousness = files.conscientiousness\n",
    "            extraversion = files.extraversion\n",
    "            agreeableness = files.agreeableness\n",
    "            neuroticism = files.neuroticism\n",
    "            \n",
    "            label = np.array([files.openness, files.conscientiousness ,files.extraversion, files.agreeableness, files.neuroticism])\n",
    "            \n",
    "            yield video_frames, files.audio_path, files.filenames, label\n",
    "            # return video_frames, label\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd60f3be-08f5-4f8d-b171-5500dc6bd874",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import facealignment\n",
    "\n",
    "\n",
    "tools = facealignment.FaceAlignmentTools()\n",
    "\n",
    "@tf.function\n",
    "def video_audio_map(video_path, audio_path, filenames, label, n_frames, training=True,output_size = (224,224), frame_step = 15):\n",
    "    \"\"\"\n",
    "        Creates frames from each video file present for each category.\n",
    "\n",
    "        Args:\n",
    "          video_path: File path to the video.\n",
    "          audio_path: Audio file to process for embeddings\n",
    "          n_frames: Number of frames to be created per video file.\n",
    "          output_size: Pixel size of the output frame image.\n",
    "\n",
    "        Return:\n",
    "          An NumPy array of frames in the shape of (n_frames, height, width, channels).\n",
    "    \"\"\"\n",
    "    # Read each video frame by frame\n",
    "    result = []\n",
    "    \n",
    "    # face_results\n",
    "    face_result = []\n",
    "    \n",
    "    src = cv2.VideoCapture(str(video_path))  \n",
    "\n",
    "    video_length = src.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "    need_length = 1 + (n_frames - 1) * frame_step\n",
    "\n",
    "    if need_length > video_length:\n",
    "        start = 0\n",
    "    else:\n",
    "        max_start = video_length - need_length\n",
    "        start = random.randint(0, max_start + 1)\n",
    "\n",
    "    src.set(cv2.CAP_PROP_POS_FRAMES, start)\n",
    "    # ret is a boolean indicating whether read was successful, frame is the image itself\n",
    "    ret, frame = src.read()\n",
    "    if ret:\n",
    "        st = time()\n",
    "        \n",
    "        ft_time = time()\n",
    "        result.append(format_frames(frame, output_size))\n",
    "        \n",
    "        # align face\n",
    "        face = tools.align(frame)\n",
    "        \n",
    "        if face is not None:\n",
    "            ft_time = time()\n",
    "            face_result.append(format_frames(face, output_size))\n",
    "            print(f\"Time for formating frame:- {time() - ft_time}\")\n",
    "        else:\n",
    "            er_t = time()\n",
    "            face_result.append(np.zeros_like(np.random.rand(224, 224, 3)))\n",
    "            print(f\"Append random array of req shape:- {time() - er_t}\")\n",
    "        \n",
    "    else:\n",
    "        er_t = time()\n",
    "        result.append(np.zeros_like(np.random.rand(224, 224, 3)))\n",
    "        \n",
    "        # face result\n",
    "        face_result.append(np.zeros_like(np.random.rand(224, 224, 3)))\n",
    "        \n",
    "    s = time()\n",
    "    for _ in range(n_frames - 1):\n",
    "        for _ in range(frame_step):\n",
    "            ret, frame = src.read()\n",
    "        if ret:\n",
    "            ft_time = time()\n",
    "            fr = format_frames(frame, output_size)\n",
    "            result.append(fr)\n",
    "            \n",
    "            # for face\n",
    "            face = tools.align(frame)\n",
    "            # face = mtcnn(frame)\n",
    "            \n",
    "            if face is not None:\n",
    "                ft_time = time()\n",
    "                face = format_frames(face, output_size)\n",
    "                face_result.append(face)\n",
    "            else:\n",
    "                er_t = time()\n",
    "                face_result.append(np.zeros_like(np.random.rand(224, 224, 3)))\n",
    "\n",
    "        else:\n",
    "            er_t = time()\n",
    "            result.append(np.zeros_like(np.random.rand(224, 224, 3)))\n",
    "            face_result.append(np.zeros_like(np.random.rand(224, 224, 3)))\n",
    "            \n",
    "            # print(f\"Append random array of req shape:- {time() - er_t}\")\n",
    "          \n",
    "    # print(f\"Time for getting aligned face from n-1 frame:- {time() - s}\")\n",
    "    src.release()\n",
    "    if len(result) < n_frames:\n",
    "        print(len(result))\n",
    "    \n",
    "    result = np.array(result)[..., [2, 1, 0]]\n",
    "    face_result = np.array(face_result)[..., [2, 1, 0]]\n",
    "    \n",
    "    # audio processing\n",
    "    # aud = load_wav_16k_mono(audio_path)\n",
    "    aud = audio_path\n",
    "    aud = extract_embedding(aud)\n",
    "    \n",
    "    # text processing\n",
    "    if training:\n",
    "        txt_inp, txt_mask = tf.py_function(get_feature_tf_data, [filenames], [tf.int64, tf.int64])\n",
    "    if training == False:\n",
    "        txt_inp, txt_mask = tf.py_function(get_feature_tf_data_test, [filenames], [tf.int64, tf.int64])\n",
    "    return result, face_result, aud, txt_inp, txt_mask, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287a10b7-02cf-4d0d-ab36-8abfd20cd435",
   "metadata": {},
   "source": [
    "# Custom checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56cddac2-c0e0-420d-849b-bdcf61babf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def generate_output_dir(outdir, run_desc):\n",
    "    prev_run_dirs = []\n",
    "    if os.path.isdir(outdir):\n",
    "        prev_run_dirs = [x for x in os.listdir(outdir) if os.path.isdir(\\\n",
    "            os.path.join(outdir, x))]\n",
    "    prev_run_ids = [re.match(r'^\\d+', x) for x in prev_run_dirs]\n",
    "    prev_run_ids = [int(x.group()) for x in prev_run_ids if x is not None]\n",
    "    cur_run_id = max(prev_run_ids, default=-1) + 1\n",
    "    run_dir = os.path.join(outdir, f'{cur_run_id:05d}-{run_desc}')\n",
    "    assert not os.path.exists(run_dir)\n",
    "    os.makedirs(run_dir)\n",
    "    return run_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ad65126-c164-4933-b598-9549b9731b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: ./checkpoint/multimodal/00000-multimodal_personality\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "outdir = \"./checkpoint/multimodal/\"\n",
    "if not os.path.isdir(outdir):\n",
    "    os.mkdir(outdir)\n",
    "\n",
    "run_desc = \"multimodal_personality\"\n",
    "\n",
    "run_dir = generate_output_dir(outdir, run_desc)\n",
    "print(f\"Results saved to: {run_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc5914f2-4f87-4a1a-851d-c4b02dea2578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "\n",
    "class MyModelCheckpoint(ModelCheckpoint):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        super().on_epoch_end(epoch,logs)\n",
    "\n",
    "        # Also save the optimizer state\n",
    "        filepath = self._get_file_path(epoch=epoch, \n",
    "                                       logs=logs, \n",
    "                                       # batch=None\n",
    "                                      )\n",
    "\n",
    "        filepath = filepath.rsplit( \".\", 1 )[ 0 ] \n",
    "        filepath += \".pkl\"\n",
    "\n",
    "        with open(filepath, 'wb') as fp:\n",
    "            pickle.dump(\n",
    "            {\n",
    "                'opt': model.optimizer.get_config(),\n",
    "                'epoch': epoch+1,\n",
    "                'lr': model.optimizer.learning_rate\n",
    "                \n",
    "             # Add additional keys if you need to store more values\n",
    "            }, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print('\\nEpoch %05d: saving optimizaer to %s' % (epoch + 1, filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4bf5d928-1d4e-4712-bcbd-e0a12631ad9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-04 08:29:11.863211: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2023-02-04 08:29:11.863238: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2023-02-04 08:29:11.864372: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1611] Profiler found 1 GPUs\n",
      "2023-02-04 08:29:11.866310: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so.11.2'; dlerror: libcupti.so.11.2: cannot open shared object file: No such file or directory\n",
      "2023-02-04 08:29:11.883778: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcupti.so\n",
      "2023-02-04 08:29:11.986361: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1661] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_INSUFFICIENT_PRIVILEGES\n",
      "2023-02-04 08:29:11.986441: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "\n",
    "checkpoint = MyModelCheckpoint(os.path.join(run_dir, 'text-personality-model-{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "        monitor='val_loss',verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "\n",
    "# tensorboard callback to visualize progress and memory bottleneck\n",
    "tboard = TensorBoard(\n",
    "    log_dir='./logs_tboard/logs',\n",
    "    histogram_freq=0,\n",
    "    write_graph=True,\n",
    "    write_images=False,\n",
    "    write_steps_per_second=False,\n",
    "    update_freq='epoch',\n",
    "    profile_batch='500,520',\n",
    ")\n",
    "\n",
    "\n",
    "# reduce lr on plateau\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_mean_acc', factor=0.5, patience=2, \n",
    "                                   verbose=1, mode='min', min_lr=0.0000000001)\n",
    "\n",
    "callbacks_list = [checkpoint, reduce_lr, tboard]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2a0084-44fd-4972-8d40-b6f32a4036d8",
   "metadata": {},
   "source": [
    "# Create data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9426c399-d91a-4264-a368-b8d1a41534c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "def combine_all_data(split='train'):\n",
    "    train_df = pd.read_csv(f\"first_impression_{split}.csv\")\n",
    "    train_df_aud = pd.read_csv(f\"first_impression_audio_{split}.csv\")\n",
    "\n",
    "    train_df_aud.drop(['extraversion', 'neuroticism', 'agreeableness', 'conscientiousness',\n",
    "           'interview', 'openness', 'file'], axis=1, inplace=True)\n",
    "    train_df_aud.columns = ['file_name', 'audio_path']\n",
    "\n",
    "    train_df = train_df.merge(train_df_aud, on='file_name')\n",
    "\n",
    "    train_text_df = pd.read_csv(f\"first_impression_text_{split}_annot.csv\")\n",
    "    train_text_df.drop(['extraversion', 'neuroticism', 'agreeableness', 'conscientiousness',\n",
    "           'interview', 'openness','file_path_video', 'file_path_audio'], axis=1, inplace=True)\n",
    "\n",
    "    train_text_df['file_name'] = train_text_df.filenames.progress_apply(lambda x: x + '.mp4')\n",
    "    train_df = train_df.merge(train_text_df, on='file_name')\n",
    "\n",
    "    train_df.to_csv(f\"first_impression_complete_annot_{split}.csv\", index=False)\n",
    "    \n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a4aa1b4a-db2b-480d-9551-7835dcc67620",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 6000/6000 [00:00<00:00, 997140.19it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df = combine_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "92122f7d-d19a-49fa-830c-f6da5677e2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 2000/2000 [00:00<00:00, 917389.33it/s]\n"
     ]
    }
   ],
   "source": [
    "val_df = combine_all_data(split='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fc0f6bc8-7649-4835-bc7d-36eb60a67827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train test\n",
    "train_df, test_df = train_test_split(train_df, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bb692c86-813e-4a44-bd73-ff0aee8eeca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = train_df.sample(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d2df89bf-ca9c-4321-b2c0-3958b5f5de85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define batch size and steps per epochs\n",
    "train_batch_size = val_batch_size = 8\n",
    "\n",
    "\n",
    "train_steps = len(train_df)//train_batch_size\n",
    "val_steps = len(test_df)//val_batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dbea5d-5632-48eb-9707-80298e20de5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da7fa0b-83a8-45d5-abb9-6cc99618dd26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3043a02c-0c2f-485e-a213-74183e4bb187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8f7636e5-4f2c-40b9-9448-f6b58e9a102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comb_mod.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "074beead-36d2-4e1a-8e36-474bc428b8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-04 08:29:13.032596: I tensorflow_io/core/kernels/cpu_check.cc:128] Your CPU supports instructions that this TensorFlow IO binary was not compiled to use: AVX2 AVX512F FMA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"StatefulPartitionedCall:1\", shape=(None, 1024), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "n_frames = 30\n",
    "train_batch_size = val_batch_size = 8\n",
    "\n",
    "\n",
    "# create tf data\n",
    "# train data\n",
    "train_ds = tf.data.Dataset.from_generator(MetaGenerator(train_df, n_frames, training=True), (tf.string, tf.string, tf.string, tf.float32))\n",
    "train_ds = train_ds.map(lambda vid_pth, aud_pth, txt_pth, lbl: video_audio_map(vid_pth, aud_pth, txt_pth, lbl, 30, training=True), tf.data.AUTOTUNE)\n",
    "train_ds = train_ds.map(\n",
    "    lambda frame, face, audio, text_inp, text_mask, label: (\n",
    "        {\n",
    "            \"input_4\": frame,\n",
    "            \"input_2\": face,\n",
    "            \"input_embedding\": audio,\n",
    "            \"input_token\": text_inp,\n",
    "            \"masked_token\": text_mask\n",
    "        }, label))\n",
    "\n",
    "\n",
    "# val data\n",
    "val_ds = tf.data.Dataset.from_generator(MetaGenerator(test_df, n_frames, training=False), (tf.string, tf.string, tf.string, tf.float32))\n",
    "val_ds = val_ds.map(lambda vid_pth, aud_pth, txt_pth, lbl: video_audio_map(vid_pth, aud_pth, txt_pth, lbl, 30, training=True), tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(\n",
    "    lambda frame, face, audio, text_inp, text_mask, label: (\n",
    "        {\n",
    "            \"input_4\": frame,\n",
    "            \"input_2\": face,\n",
    "            \"input_embedding\": audio,\n",
    "            \"input_token\": text_inp,\n",
    "            \"masked_token\": text_mask\n",
    "        }, label))\n",
    "\n",
    "\n",
    "# test data\n",
    "test_ds = tf.data.Dataset.from_generator(MetaGenerator(val_df, n_frames, training=False), (tf.string, tf.string, tf.string, tf.float32))\n",
    "test_ds = test_ds.map(lambda vid_pth, aud_pth, txt_pth, lbl: video_audio_map(vid_pth, aud_pth, txt_pth, lbl, 30, training=False), tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.map(\n",
    "    lambda frame, face, audio, text_inp, text_mask, label: (\n",
    "        {\n",
    "            \"input_4\": frame,\n",
    "            \"input_2\": face,\n",
    "            \"input_embedding\": audio,\n",
    "            \"input_token\": text_inp,\n",
    "            \"masked_token\": text_mask\n",
    "        }, label))\n",
    "\n",
    "\n",
    "\n",
    "# for ele in test_ds:\n",
    "#     print(ele)\n",
    "#     break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b65517c9-1903-45c4-92b0-68d77bb6c84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img1 = None\n",
    "# img2 = None\n",
    "\n",
    "# for i,j in enumerate(train_ds):\n",
    "#     img1 = j[0]['input_4'].numpy()    \n",
    "    \n",
    "#     if i == 20:\n",
    "#         img2 = j[0]['input_4'].numpy()\n",
    "#         break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd6b6e4-773e-46c4-a981-4ecceaad68fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d48782eb-d190-489f-9b97-5cd116fd7d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_ds = train_ds.repeat().batch(train_batch_size)\n",
    "val_ds = val_ds.batch(val_batch_size)\n",
    "test_ds = test_ds.batch(val_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef19f0e-97e0-4802-9466-62b6175992f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f027f13e-b823-45a7-a80d-f20e65f70303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = comb_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "feb9be11-c73e-4242-bd00-567e6c1fe745",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = ['mae'],\n",
    "    # loss = tf.keras.losses.BinaryCrossentropy(from_logits=True), \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001), \n",
    "    metrics = [mean_acc]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a546b988-0bd7-47b0-b60b-d3883d271b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babb8bfe-8383-4195-baf5-522c8c734b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mount1/miniconda3/envs/tfgpu2.5/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n",
      "2023-02-04 08:29:15.128758: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-02-04 08:29:15.129210: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2200215000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-04 08:29:40.914185: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2023-02-04 08:29:45.014099: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-02-04 08:29:45.014177: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-02-04 08:29:45.014390: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-02-04 08:29:48.212350: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8201\n",
      "2023-02-04 08:29:51.839430: W tensorflow/stream_executor/gpu/asm_compiler.cc:191] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.0\n",
      "2023-02-04 08:29:51.839460: W tensorflow/stream_executor/gpu/asm_compiler.cc:194] Used ptxas at ptxas\n",
      "2023-02-04 08:29:51.839534: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Unimplemented: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499/600 [=======================>......] - ETA: 1:29 - loss: 0.1106 - mean_acc: 0.8894"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-04 08:37:18.139284: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2023-02-04 08:37:18.139318: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2023-02-04 08:37:18.258466: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1661] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_INSUFFICIENT_PRIVILEGES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "520/600 [=========================>....] - ETA: 1:11 - loss: 0.1103 - mean_acc: 0.8897"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-04 08:37:36.934791: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2023-02-04 08:37:37.757815: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2023-02-04 08:37:38.331713: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2023-02-04 08:37:39.153371: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: ./logs_tboard/logs/train/plugins/profile/2023_02_04_08_37_38\n",
      "2023-02-04 08:37:39.616218: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to ./logs_tboard/logs/train/plugins/profile/2023_02_04_08_37_38/gpu-vision-2.trace.json.gz\n",
      "2023-02-04 08:37:40.293187: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: ./logs_tboard/logs/train/plugins/profile/2023_02_04_08_37_38\n",
      "2023-02-04 08:37:40.307232: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to ./logs_tboard/logs/train/plugins/profile/2023_02_04_08_37_38/gpu-vision-2.memory_profile.json.gz\n",
      "2023-02-04 08:37:40.319770: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: ./logs_tboard/logs/train/plugins/profile/2023_02_04_08_37_38Dumped tool data for xplane.pb to ./logs_tboard/logs/train/plugins/profile/2023_02_04_08_37_38/gpu-vision-2.xplane.pb\n",
      "Dumped tool data for overview_page.pb to ./logs_tboard/logs/train/plugins/profile/2023_02_04_08_37_38/gpu-vision-2.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to ./logs_tboard/logs/train/plugins/profile/2023_02_04_08_37_38/gpu-vision-2.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to ./logs_tboard/logs/train/plugins/profile/2023_02_04_08_37_38/gpu-vision-2.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to ./logs_tboard/logs/train/plugins/profile/2023_02_04_08_37_38/gpu-vision-2.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 685s 1s/step - loss: 0.1095 - mean_acc: 0.8905 - val_loss: 0.1054 - val_mean_acc: 0.8946\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10537, saving model to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-01-0.11.h5\n",
      "\n",
      "Epoch 00001: saving optimizaer to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-01-0.11.pkl\n",
      "Epoch 2/50\n",
      "600/600 [==============================] - 638s 1s/step - loss: 0.1045 - mean_acc: 0.8955 - val_loss: 0.1040 - val_mean_acc: 0.8960\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10537 to 0.10398, saving model to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-02-0.10.h5\n",
      "\n",
      "Epoch 00002: saving optimizaer to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-02-0.10.pkl\n",
      "Epoch 3/50\n",
      "600/600 [==============================] - 636s 1s/step - loss: 0.1030 - mean_acc: 0.8970 - val_loss: 0.1042 - val_mean_acc: 0.8958\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10398\n",
      "\n",
      "Epoch 00003: saving optimizaer to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-03-0.10.pkl\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 4/50\n",
      "600/600 [==============================] - 638s 1s/step - loss: 0.1016 - mean_acc: 0.8984 - val_loss: 0.1028 - val_mean_acc: 0.8972\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.10398 to 0.10285, saving model to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-04-0.10.h5\n",
      "\n",
      "Epoch 00004: saving optimizaer to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-04-0.10.pkl\n",
      "Epoch 5/50\n",
      "600/600 [==============================] - 637s 1s/step - loss: 0.1010 - mean_acc: 0.8990 - val_loss: 0.1019 - val_mean_acc: 0.8981\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.10285 to 0.10188, saving model to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-05-0.10.h5\n",
      "\n",
      "Epoch 00005: saving optimizaer to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-05-0.10.pkl\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 6/50\n",
      "600/600 [==============================] - 634s 1s/step - loss: 0.1005 - mean_acc: 0.8995 - val_loss: 0.1017 - val_mean_acc: 0.8983\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.10188 to 0.10173, saving model to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-06-0.10.h5\n",
      "\n",
      "Epoch 00006: saving optimizaer to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-06-0.10.pkl\n",
      "Epoch 7/50\n",
      "600/600 [==============================] - 635s 1s/step - loss: 0.1003 - mean_acc: 0.8997 - val_loss: 0.1015 - val_mean_acc: 0.8985\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.10173 to 0.10150, saving model to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-07-0.10.h5\n",
      "\n",
      "Epoch 00007: saving optimizaer to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-07-0.10.pkl\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 8/50\n",
      "600/600 [==============================] - 636s 1s/step - loss: 0.0997 - mean_acc: 0.9003 - val_loss: 0.1010 - val_mean_acc: 0.8990\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.10150 to 0.10104, saving model to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-08-0.10.h5\n",
      "\n",
      "Epoch 00008: saving optimizaer to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-08-0.10.pkl\n",
      "Epoch 9/50\n",
      "600/600 [==============================] - 638s 1s/step - loss: 0.0995 - mean_acc: 0.9005 - val_loss: 0.1016 - val_mean_acc: 0.8984\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.10104\n",
      "\n",
      "Epoch 00009: saving optimizaer to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-09-0.10.pkl\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 10/50\n",
      "600/600 [==============================] - 639s 1s/step - loss: 0.0993 - mean_acc: 0.9007 - val_loss: 0.1010 - val_mean_acc: 0.8990\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.10104 to 0.10099, saving model to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-10-0.10.h5\n",
      "\n",
      "Epoch 00010: saving optimizaer to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-10-0.10.pkl\n",
      "Epoch 11/50\n",
      "600/600 [==============================] - 638s 1s/step - loss: 0.0992 - mean_acc: 0.9008 - val_loss: 0.1012 - val_mean_acc: 0.8988\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.10099\n",
      "\n",
      "Epoch 00011: saving optimizaer to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-11-0.10.pkl\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 12/50\n",
      "600/600 [==============================] - 634s 1s/step - loss: 0.0990 - mean_acc: 0.9010 - val_loss: 0.1009 - val_mean_acc: 0.8991\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.10099 to 0.10091, saving model to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-12-0.10.h5\n",
      "\n",
      "Epoch 00012: saving optimizaer to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-12-0.10.pkl\n",
      "Epoch 13/50\n",
      "600/600 [==============================] - 638s 1s/step - loss: 0.0990 - mean_acc: 0.9010 - val_loss: 0.1010 - val_mean_acc: 0.8990\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.10091\n",
      "\n",
      "Epoch 00013: saving optimizaer to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-13-0.10.pkl\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "Epoch 14/50\n",
      "600/600 [==============================] - 639s 1s/step - loss: 0.0990 - mean_acc: 0.9010 - val_loss: 0.1009 - val_mean_acc: 0.8991\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.10091\n",
      "\n",
      "Epoch 00014: saving optimizaer to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-14-0.10.pkl\n",
      "Epoch 15/50\n",
      "600/600 [==============================] - 638s 1s/step - loss: 0.0989 - mean_acc: 0.9011 - val_loss: 0.1010 - val_mean_acc: 0.8990\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.10091\n",
      "\n",
      "Epoch 00015: saving optimizaer to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-15-0.10.pkl\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "Epoch 16/50\n",
      "600/600 [==============================] - 637s 1s/step - loss: 0.0989 - mean_acc: 0.9011 - val_loss: 0.1009 - val_mean_acc: 0.8991\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.10091\n",
      "\n",
      "Epoch 00016: saving optimizaer to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-16-0.10.pkl\n",
      "Epoch 17/50\n",
      "600/600 [==============================] - 633s 1s/step - loss: 0.0989 - mean_acc: 0.9011 - val_loss: 0.1009 - val_mean_acc: 0.8991\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.10091\n",
      "\n",
      "Epoch 00017: saving optimizaer to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-17-0.10.pkl\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "Epoch 18/50\n",
      "600/600 [==============================] - 637s 1s/step - loss: 0.0989 - mean_acc: 0.9011 - val_loss: 0.1009 - val_mean_acc: 0.8991\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.10091 to 0.10091, saving model to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-18-0.10.h5\n",
      "\n",
      "Epoch 00018: saving optimizaer to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-18-0.10.pkl\n",
      "Epoch 19/50\n",
      "600/600 [==============================] - 637s 1s/step - loss: 0.0989 - mean_acc: 0.9011 - val_loss: 0.1009 - val_mean_acc: 0.8991\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.10091 to 0.10090, saving model to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-19-0.10.h5\n",
      "\n",
      "Epoch 00019: saving optimizaer to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-19-0.10.pkl\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "Epoch 20/50\n",
      "600/600 [==============================] - 635s 1s/step - loss: 0.0988 - mean_acc: 0.9012 - val_loss: 0.1009 - val_mean_acc: 0.8991\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.10090\n",
      "\n",
      "Epoch 00020: saving optimizaer to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-20-0.10.pkl\n",
      "Epoch 21/50\n",
      "600/600 [==============================] - 634s 1s/step - loss: 0.0988 - mean_acc: 0.9012 - val_loss: 0.1009 - val_mean_acc: 0.8991\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.10090 to 0.10090, saving model to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-21-0.10.h5\n",
      "\n",
      "Epoch 00021: saving optimizaer to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-21-0.10.pkl\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "Epoch 22/50\n",
      "600/600 [==============================] - 631s 1s/step - loss: 0.0988 - mean_acc: 0.9012 - val_loss: 0.1009 - val_mean_acc: 0.8991\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.10090 to 0.10090, saving model to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-22-0.10.h5\n",
      "\n",
      "Epoch 00022: saving optimizaer to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-22-0.10.pkl\n",
      "Epoch 23/50\n",
      "600/600 [==============================] - 631s 1s/step - loss: 0.0988 - mean_acc: 0.9012 - val_loss: 0.1009 - val_mean_acc: 0.8991\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.10090 to 0.10090, saving model to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-23-0.10.h5\n",
      "\n",
      "Epoch 00023: saving optimizaer to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-23-0.10.pkl\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 24/50\n",
      "600/600 [==============================] - 634s 1s/step - loss: 0.0988 - mean_acc: 0.9012 - val_loss: 0.1009 - val_mean_acc: 0.8991\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.10090\n",
      "\n",
      "Epoch 00024: saving optimizaer to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-24-0.10.pkl\n",
      "Epoch 25/50\n",
      "600/600 [==============================] - 632s 1s/step - loss: 0.0988 - mean_acc: 0.9012 - val_loss: 0.1009 - val_mean_acc: 0.8991\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.10090 to 0.10090, saving model to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-25-0.10.h5\n",
      "\n",
      "Epoch 00025: saving optimizaer to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-25-0.10.pkl\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 26/50\n",
      "600/600 [==============================] - 633s 1s/step - loss: 0.0988 - mean_acc: 0.9012 - val_loss: 0.1009 - val_mean_acc: 0.8991\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.10090 to 0.10090, saving model to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-26-0.10.h5\n",
      "\n",
      "Epoch 00026: saving optimizaer to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-26-0.10.pkl\n",
      "Epoch 27/50\n",
      "600/600 [==============================] - 635s 1s/step - loss: 0.0988 - mean_acc: 0.9012 - val_loss: 0.1009 - val_mean_acc: 0.8991\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.10090 to 0.10090, saving model to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-27-0.10.h5\n",
      "\n",
      "Epoch 00027: saving optimizaer to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-27-0.10.pkl\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 28/50\n",
      "600/600 [==============================] - 634s 1s/step - loss: 0.0988 - mean_acc: 0.9012 - val_loss: 0.1009 - val_mean_acc: 0.8991\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.10090\n",
      "\n",
      "Epoch 00028: saving optimizaer to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-28-0.10.pkl\n",
      "Epoch 29/50\n",
      "600/600 [==============================] - 633s 1s/step - loss: 0.0988 - mean_acc: 0.9012 - val_loss: 0.1009 - val_mean_acc: 0.8991\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.10090\n",
      "\n",
      "Epoch 00029: saving optimizaer to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-29-0.10.pkl\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 6.103515470812226e-09.\n",
      "Epoch 30/50\n",
      "600/600 [==============================] - 633s 1s/step - loss: 0.0988 - mean_acc: 0.9012 - val_loss: 0.1009 - val_mean_acc: 0.8991\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.10090\n",
      "\n",
      "Epoch 00030: saving optimizaer to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-30-0.10.pkl\n",
      "Epoch 31/50\n",
      "600/600 [==============================] - 633s 1s/step - loss: 0.0988 - mean_acc: 0.9012 - val_loss: 0.1009 - val_mean_acc: 0.8991\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.10090\n",
      "\n",
      "Epoch 00031: saving optimizaer to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-31-0.10.pkl\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 3.051757735406113e-09.\n",
      "Epoch 32/50\n",
      "600/600 [==============================] - 633s 1s/step - loss: 0.0988 - mean_acc: 0.9012 - val_loss: 0.1009 - val_mean_acc: 0.8991\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.10090\n",
      "\n",
      "Epoch 00032: saving optimizaer to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-32-0.10.pkl\n",
      "Epoch 33/50\n",
      "600/600 [==============================] - 632s 1s/step - loss: 0.0988 - mean_acc: 0.9012 - val_loss: 0.1009 - val_mean_acc: 0.8991\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.10090\n",
      "\n",
      "Epoch 00033: saving optimizaer to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-33-0.10.pkl\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.5258788677030566e-09.\n",
      "Epoch 34/50\n",
      "600/600 [==============================] - 633s 1s/step - loss: 0.0988 - mean_acc: 0.9012 - val_loss: 0.1009 - val_mean_acc: 0.8991\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.10090\n",
      "\n",
      "Epoch 00034: saving optimizaer to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-34-0.10.pkl\n",
      "Epoch 35/50\n",
      "600/600 [==============================] - 631s 1s/step - loss: 0.0988 - mean_acc: 0.9012 - val_loss: 0.1009 - val_mean_acc: 0.8991\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.10090\n",
      "\n",
      "Epoch 00035: saving optimizaer to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-35-0.10.pkl\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 7.629394338515283e-10.\n",
      "Epoch 36/50\n",
      "600/600 [==============================] - 632s 1s/step - loss: 0.0988 - mean_acc: 0.9012 - val_loss: 0.1009 - val_mean_acc: 0.8991\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.10090\n",
      "\n",
      "Epoch 00036: saving optimizaer to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-36-0.10.pkl\n",
      "Epoch 37/50\n",
      "600/600 [==============================] - 633s 1s/step - loss: 0.0988 - mean_acc: 0.9012 - val_loss: 0.1009 - val_mean_acc: 0.8991\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.10090\n",
      "\n",
      "Epoch 00037: saving optimizaer to ./checkpoint/multimodal/00000-multimodal_personality/text-personality-model-37-0.10.pkl\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 3.8146971692576415e-10.\n",
      "Epoch 38/50\n",
      " 45/600 [=>............................] - ETA: 8:07 - loss: 0.0925 - mean_acc: 0.9075"
     ]
    }
   ],
   "source": [
    "model.fit(x= train_ds, steps_per_epoch=train_steps, \n",
    "               validation_data=val_ds,validation_steps=val_steps,\n",
    "               epochs=50, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa8b7cd-d407-4383-b5c3-65412a507985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb55d23-8de3-43a6-b487-f5f95338428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd892de1-4b55-4915-bd85-b782358f8d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ca14e3-e712-4e8d-949d-6fd4dac35841",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu2.5",
   "language": "python",
   "name": "tfgpu2.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
